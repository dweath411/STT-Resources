knitr::opts_chunk$set(echo = TRUE)
library(FNN)
library(class)
library(dplyr)
library(MASS)
library(corrplot)
library(ggcorrplot)
library(ggplot2)
library(glmnet)
library(gpairs)
library(leaps)
library(boot)
library(tree)
library(gbm)
library(splines)
library(gam)
library(randomForest)
library(car)
library(rpart)
library(rpart.plot)
train <- read.csv("train_new.csv")
knitr::opts_chunk$set(echo = TRUE)
# Load libraries
library(ISLR)
library(MASS)
library(gam)
library(glmnet)
library(boot)
library(leaps)
library(rpart)
library(randomForest)
library(splines)
library(tree)
library(gbm)
data("Hitters")
Hitters <- Hitters[!is.na(Hitters$Salary),]
set.seed(1111)
train.h <- sample(nrow(Hitters), 200)
Hitters.train <- Hitters[train.h,]
Hitters.test <- Hitters[-train.h,]
fwd.hitters <- regsubsets(log(Salary) ~ ., data = Hitters.train, method = 'forward', nvmax = ncol(Hitters.train))
fwd.summary.hitters <- summary(fwd.hitters)
which.min(fwd.summary.hitters$bic)
which.min(fwd.summary.hitters$adjr2)
which.min(fwd.summary.hitters$cp) # will use the cp value
coef(fwd.hitters, id = 3)
hitters.gam <- gam(log(Salary) ~ s(Hits, df = 2) + s(CRuns, df = 2) + League, data = Hitters.train)
par(mfrow = c(2,2))
plot(hitters.gam, se = T, col = "blue")
summary(hitters.gam)
hitters.gam.test <- gam(log(Salary) ~ s(Hits, df = 4) + s(CRuns, df = 4) + League, data = Hitters.test)
par(mfrow = c(2,2))
plot(hitters.gam.test, se = T, col = "blue")
summary(hitters.gam.test)
data("Credit")
set.seed(1234)
Credit <- Credit[,-1] # remove ID column
train.c <- sample(nrow(Credit), 300)
Credit.train <- Credit[train.c,]
Credit.test <- Credit[-train.c,]
credit.tree <- tree(Balance ~ ., data = Credit.train)
summary(credit.tree)
# MSE
credit.pred.train <- predict(credit.tree, newdata = Credit.train)
actual.train <-Credit.train$Balance
plot(credit.pred.train, actual.train)
abline(0,1)
round(mean((credit.pred.train-actual.train)^2))
credit.tree
plot(credit.tree)
text(credit.tree, pretty = 0)
credit.pred.test <- predict(credit.tree, newdata = Credit.test)
head(credit.pred.test)
actual.test <-Credit.test$Balance
plot(credit.pred.test, actual.test)
abline(0,1)
round(mean((credit.pred.test-actual.test)^2))
cv.credit <- cv.tree(credit.tree)
best.size <- cv.credit$size[which.min(cv.credit$dev)]
best.size
plot(cv.credit$k, cv.credit$dev, type = "b") # main plot
plot(cv.credit$size, cv.credit$dev, type = "b")
#prune.credit <- prune.tree(credit.tree, best = best.size) #use prune.misclass for next part
#plot(prune.credit) # the plot is the same
#text(prune.credit, pretty = 0)
#prune.credit
prune.credit <- prune.tree(credit.tree, best = 5)
plot(prune.credit)
text(prune.credit, pretty = 0)
prune.credit
# PRUNED TRAINING MSE
credit.train.prune.pred <- predict(prune.credit, newdata = Credit.train)
actual.train.credit <-Credit.train$Balance
plot(credit.train.prune.pred, actual.train.credit)
abline(0,1)
(mean((credit.train.prune.pred-actual.train.credit)^2))
# UNPRUNED TRAINING MSE
credit.pred.train <- predict(credit.tree, newdata = Credit.train)
plot(credit.pred.train, actual.train)
abline(0,1)
(mean((credit.pred.train-actual.train)^2))
# PRUNED TEST MSE
credit.test.prune.pred <- predict(prune.credit, newdata = Credit.test)
actual.test <-Credit.test$Balance
plot(credit.test.prune.pred, actual.test)
abline(0,1)
(mean((credit.test.prune.pred-actual.test)^2))
# UNPRUNED TEST MSE
credit.pred.test <- predict(credit.tree, newdata = Credit.test)
plot(credit.pred.test, actual.test)
abline(0,1)
(mean((credit.pred.test-actual.test)^2))
ncol(Credit.train) - 1 # number of predictors
bag.credit <- randomForest(Balance ~ ., data = Credit.train, mtry = 10, ntree = 1000, importance = T)
importance(bag.credit)
varImpPlot(bag.credit)
bag.credit.pred <- predict(bag.credit, newdata = Credit.test)
head(bag.credit.pred) # predicting response
actual.test <-Credit.test$Balance
plot(bag.credit.pred, actual.test)
abline(0,1)
(mean((bag.credit.pred-actual.test)^2))
sqrt(ncol(Credit.train) - 1)
rf.credit <- randomForest(Balance ~ ., data = Credit.train, mtry = 3, importance = T, ntree = 1000)
rf.credit
importance(rf.credit)
varImpPlot(rf.credit)
rf.credit.pred <- predict(rf.credit, newdata = Credit.test)
actual.test <-Credit.test$Balance
plot(rf.credit.pred, actual.test)
abline(0,1)
(mean((rf.credit.pred-actual.test)^2))
credit.boost <- gbm(Balance ~., data = Credit.train, distribution = "gaussian", n.trees = 1000, shrinkage = 0.01)
credit.boost
summary(credit.boost)
#First, we need to find the best number of trees.
credit.boost.cv <- gbm(Balance ~ ., data = Credit.train,
distribution = "gaussian", shrinkage = 0.01,
n.tree = 1000, cv.folds = 10)
which.min(credit.boost.cv$cv.error)
# 1000 trees is the best number of trees to make predictions with.
credit.boost.pred <- predict(credit.boost, newdata = Credit.test, n.trees = which.min(credit.boost.cv$cv.error))
actual.test <-Credit.test$Balance
plot(credit.boost.pred, actual.test)
abline(0,1)
(mean((credit.boost.pred-actual.test)^2))
credit.gam <- gam(Balance ~ s(Income, df = 2) + s(Limit, df = 2) + s(Rating, df = 2) + s(Cards, df = 3) + s(Age, df = 3) + s(Education, df = 3) + Gender + Student + Married + Ethnicity, data = Credit.train)
par(mfrow = c(2,2))
plot(credit.gam, se = T, col = "darkgreen")
summary(credit.gam)
# Compute test MSE
gam.credit.pred <- predict(credit.gam, newdata = Credit.test)
actual.test <-Credit.test$Balance
plot(gam.credit.pred, actual.test)
abline(0,1)
(mean((gam.credit.pred-actual.test)^2))
print(c("unpruned tree mse: ",(mean((credit.pred.test-actual.test)^2)))) # unpruned tree
print(c("pruned tree mse: ",(mean((credit.test.prune.pred-actual.test)^2)))) # pruned tree
print(c("bagging mse: ",(mean((bag.credit.pred-actual.test)^2)))) # bagging
print(c("random forest mse: ",(mean((rf.credit.pred-actual.test)^2)))) # random forest
print(c("boosting mse: ",(mean((credit.boost.pred-actual.test)^2)))) # boosting
print(c("gam mse: ",(mean((gam.credit.pred-actual.test)^2)))) # gam
data("OJ")
set.seed(200)
train.o <- sample(nrow(OJ), 800)
OJ.train <- OJ[train.o,]
OJ.test <- OJ[-train.o,]
OJ.tree <- tree(Purchase ~ ., data = OJ.train)
summary(OJ.tree)
OJ.tree
plot(OJ.tree)
text(OJ.tree, pretty = 0)
OJ.test.pred <- predict(OJ.tree, OJ.test, type = "class")
table(OJ.test.pred, OJ.test$Purchase)
mean(OJ.test.pred != OJ.test$Purchase)
cv.oj <- cv.tree(OJ.tree, FUN = prune.misclass)
names(cv.oj)
cv.oj
plot(cv.oj$size, cv.oj$dev, type = "b")
which.min(cv.oj$size) # 4 is the lowest
which.min(cv.oj$size)
prune.oj <- prune.misclass(OJ.tree, best = 4)
plot(prune.oj)
text(prune.oj, pretty = 0)
summary(OJ.tree)
summary(prune.oj)
OJ.test.pred <- predict(OJ.tree, OJ.test, type = "class")
table(OJ.test.pred, OJ.test$Purchase)
print(c("Unpruned test error rate",mean(OJ.test.pred != OJ.test$Purchase)))
OJ.prune.pred <- predict(prune.oj, OJ.test, type = "class")
table(OJ.prune.pred, OJ.test$Purchase)
print(c("Pruned test error rate",mean(OJ.prune.pred != OJ.test$Purchase)))
ncol(OJ.train) - 1
bag.oj <- randomForest(Purchase ~ ., data = OJ.train, mtry = 17, ntree = 1000, importance = T)
bag.oj
importance(bag.oj)
varImpPlot(bag.oj)
bag.oj.pred <- predict(bag.oj, newdata = OJ.test)
table(bag.oj.pred, OJ.test$Purchase)
mean(bag.oj.pred != OJ.test$Purchase)
sqrt(ncol(OJ.train) -1)
rf.oj <- randomForest(Purchase ~ ., data = OJ.train, mtry = 4, importance = T)
rf.oj
importance(rf.oj)
varImpPlot(rf.oj)
rf.oj.pred <- predict(rf.oj, newdata = OJ.test)
table(rf.oj.pred, OJ.test$Purchase)
mean(rf.oj.pred != OJ.test$Purchase)
binary.purchase <- ifelse(OJ.train$Purchase == "CH", 1,0)
boost.oj <- gbm(binary.purchase ~ ., data = OJ.train[,colnames(OJ.train) != "Purchase"], distribution = "bernoulli", shrinkage = 0.01, n.trees = 1000)
boost.oj
summary(boost.oj)
# First, do cross-validation to find the best number of trees
boost.cv.oj <- gbm(binary.purchase ~ ., data = OJ.train[,colnames(OJ.train) != "Purchase"], distribution = "bernoulli", shrinkage = 0.01, n.trees = 1000, cv.folds = 10)
which.min(boost.cv.oj$cv.error) # 900 trees is the best
# now perform predictions with 900 trees
boost.oj.pred <- predict(boost.cv.oj, newdata = OJ.test, n.trees = 900, type = "response")
boost.oj.pred <- ifelse(boost.oj.pred > 0.5, "CH", "MM")
table(boost.oj.pred, OJ.test$Purchase)
mean(boost.oj.pred != OJ.test$Purchase)
log.oj <- glm(binary.purchase ~ ., data = OJ.train[,colnames(OJ.train) != "Purchase"], family = binomial(link = "logit"))
log.oj.pred <- predict(log.oj, newdata = OJ.test, type = "response")
log.oj.pred <- ifelse(log.oj.pred > 0.5, "CH", "MM")
mean(log.oj.pred != OJ.test$Purchase)
summary(log.oj)
print(c("Unpruned test error rate",mean(OJ.test.pred != OJ.test$Purchase)))
print(c("Pruned test error rate",mean(OJ.prune.pred != OJ.test$Purchase)))
print(c("Bagging test error rate",mean(bag.oj.pred != OJ.test$Purchase)))
print(c("Random Forest test error rate",mean(rf.oj.pred != OJ.test$Purchase)))
print(c("Boosting test error rate",mean(boost.oj.pred != OJ.test$Purchase)))
print(c("Logistic Regression test error rate",mean(log.oj.pred != OJ.test$Purchase)))
knitr::opts_chunk$set(echo = TRUE)
library(FNN)
library(class)
library(dplyr)
library(MASS)
library(corrplot)
library(ggcorrplot)
library(ggplot2)
library(glmnet)
library(gpairs)
library(leaps)
library(boot)
library(tree)
library(gbm)
library(splines)
library(gam)
library(randomForest)
library(car)
library(rpart)
library(rpart.plot)
train <- read.csv("train_new.csv")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(sqldf)
library(tidyr)
library(MASS)
library(stringr)
library(ggplot2)
library(ggcorrplot)
library(glmnet)
library(tree)
library(rpart)
library(rpart.plot)
library(leaps)
library(randomForest)
gini <- read.csv("gini1.csv")
